{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "## Import usual libraries\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import backend\n",
    "from datetime import datetime #DB\n",
    "from keras.utils import plot_model #DB\n",
    "from keras.preprocessing.image import ImageDataGenerator #DB\n",
    "import gc #DB\n",
    "\n",
    "from config import fcn_config as cfg\n",
    "from config import fcn8_cnn as cnn\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPSCALE =  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UPSCALE = False\n",
    "print(\"UPSCALE = \", UPSCALE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "HEIGHT = cfg.HEIGHT\n",
    "WIDTH  = cfg.WIDTH\n",
    "N_CLASSES = cfg.NUM_CLASSES\n",
    "\n",
    "BATCH_SIZE = cfg.BATCH_SIZE\n",
    "EPOCHS = cfg.EPOCHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 7, 7, 512)    12845568    block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool4_11 (Conv2D)               (None, 14, 14, 12)   6156        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 7, 7, 512)    262656      conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 28, 28, 12)   576         pool4_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_11 (Conv2D)               (None, 28, 28, 12)   3084        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 28, 28, 12)   98304       conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_layer (Add)                 (None, 28, 28, 12)   0           conv2d_transpose_17[0][0]        \n",
      "                                                                 pool3_11[0][0]                   \n",
      "                                                                 conv2d_transpose_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 224, 224, 12) 9216        add_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 224, 224, 12) 0           conv2d_transpose_18[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 27,940,248\n",
      "Trainable params: 27,940,248\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dir_data = cfg.DATASET_DIR\n",
    "dir_train_img = cfg.dir_train_img\n",
    "dir_train_seg = cfg.dir_train_seg\n",
    "dir_test_img  = cfg.dir_test_img\n",
    "dir_test_seg  = cfg.dir_test_seg\n",
    "dir_calib_img = cfg.dir_calib_img\n",
    "dir_calib_seg = cfg.dir_calib_seg\n",
    "dir_valid_img = cfg.dir_valid_img\n",
    "dir_valid_seg = cfg.dir_valid_seg\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# model a\n",
    "######################################################################\n",
    "\n",
    "#model = UNET((HEIGHT, WIDTH, 3))\n",
    "\n",
    "model = cnn.FCN8(nClasses     = N_CLASSES,\n",
    "             input_height = HEIGHT,\n",
    "             input_width  = WIDTH,\n",
    "             upscale   = UPSCALE)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def plots():\n",
    "    if UPSCALE==\"True\" :\n",
    "            plot_model(model, to_file=\"rpt/fcn8ups_model\" +  str(WIDTH) + \"x\" + str(HEIGHT) + \".png\", show_shapes=True)\n",
    "    else :\n",
    "            plot_model(model, to_file=\"rpt/fcn8_model\"    +  str(WIDTH) + \"x\" + str(HEIGHT) + \".png\", show_shapes=True)\n",
    "\n",
    "#plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311, 224, 224, 3) (311, 224, 224, 12)\n"
     ]
    }
   ],
   "source": [
    "# load training images\n",
    "train_images = os.listdir(dir_train_img)\n",
    "train_images.sort()\n",
    "train_segmentations  = os.listdir(dir_train_seg)\n",
    "train_segmentations.sort()\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for im , seg in zip(train_images,train_segmentations) :\n",
    "    X_train.append( cnn.NormalizeImageArr(os.path.join(dir_train_img,im) ))\n",
    "    Y_train.append( cnn.LoadSegmentationArr( os.path.join(dir_train_seg,seg) , N_CLASSES , WIDTH, HEIGHT)  )\n",
    "\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "#np.unique(Y_train) \n",
    "#array([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 224, 224, 3) (56, 224, 224, 12)\n"
     ]
    }
   ],
   "source": [
    "# load validation images\n",
    "valid_images = os.listdir(dir_valid_img)\n",
    "valid_images.sort()\n",
    "valid_segmentations  = os.listdir(dir_valid_seg)\n",
    "valid_segmentations.sort()\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "for im , seg in zip(valid_images,valid_segmentations) :\n",
    "    X_valid.append( cnn.NormalizeImageArr(os.path.join(dir_valid_img,im)) )\n",
    "    Y_valid.append( cnn.LoadSegmentationArr( os.path.join(dir_valid_seg,seg) , N_CLASSES , WIDTH, HEIGHT)  )\n",
    "X_valid, Y_valid = np.array(X_valid) , np.array(Y_valid)\n",
    "print(X_valid.shape,Y_valid.shape)\n",
    "\n",
    "X_valid, Y_valid = shuffle(X_valid, Y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"train_ck/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "callbacks = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                             save_weights_only=True,\n",
    "                                             verbose=1)\n",
    "\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=1E-2, decay=5**(-4), momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#callbacks_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hagi/Desktop/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/hagi/Desktop/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 311 samples, validate on 56 samples\n",
      "Epoch 1/200\n",
      " - 157s - loss: 2.6120 - acc: 0.0837 - val_loss: 2.4845 - val_acc: 0.0879\n",
      "Epoch 2/200\n",
      " - 162s - loss: 2.4831 - acc: 0.0908 - val_loss: 2.4815 - val_acc: 0.0946\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fd7dee7ad9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstartTime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#DB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mendTime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiff1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendTime1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "startTime1 = datetime.now() #DB\n",
    "hist1 = model.fit(X_train,Y_train, validation_data=(X_valid,Y_valid), batch_size=BATCH_SIZE,epochs=EPOCHS, callbacks=[callbacks], verbose=2)\n",
    "endTime1 = datetime.now()\n",
    "diff1 = endTime1 - startTime1\n",
    "print(\"\\n\")\n",
    "print(\"Elapsed time for Keras training (s): \", diff1.total_seconds())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-746734d1a1e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUPSCALE\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"True\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist1' is not defined"
     ]
    }
   ],
   "source": [
    "for key in [\"loss\", \"val_loss\"]:\n",
    "    plt.plot(hist1.history[key],label=key)\n",
    "plt.legend()\n",
    "\n",
    "if UPSCALE==\"True\" :\n",
    "        plt.savefig(\"rpt/fcn8ups_training_curves_\" + str(WIDTH) + \"x\" + str(HEIGHT) + \".png\")\n",
    "else :\n",
    "        plt.savefig(\"rpt/fcn8_training_curves_\" + str(WIDTH) + \"x\" + str(HEIGHT) + \".png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save model\n",
    "if UPSCALE==\"True\" :\n",
    "        model.save(\"keras_model/fcn8ups/ep\" + str(EPOCHS) + \"_trained_fcn8ups_\" + str(WIDTH) + \"x\" + str(HEIGHT) + \".hdf5\")\n",
    "else :\n",
    "        model.save(\"keras_model/fcn8/ep\" + str(EPOCHS) + \"_trained_fcn8_\" + str(WIDTH) + \"x\" + str(HEIGHT) + \".hdf5\")\n",
    "\n",
    "\n",
    "print(\"\\nEnd of FCN8 training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(model_filename) #DB\n",
    "\n",
    "print(\"\\nnow computing IoU over testing data set:\")\n",
    "y_pred1   = model.predict(X_test)\n",
    "y_pred1_i = np.argmax(y_pred1, axis=3)\n",
    "y_test1_i = np.argmax(Y_test, axis=3)\n",
    "#print(y_test1_i.shape,y_pred1_i.shape)\n",
    "cnn.IoU(y_test1_i, y_pred1_i)\n",
    "\n",
    "print(\"\\nnow computing IoU over validation data set:\")\n",
    "y_pred2 = model.predict(X_valid)\n",
    "y_pred2_i = np.argmax(y_pred2, axis=3)\n",
    "y_test2_i = np.argmax(Y_valid, axis=3)\n",
    "#print(y_test2_i.shape,y_pred2_i.shape)\n",
    "cnn.IoU(y_test2_i,y_pred2_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def visalize_prediction(model, img):\n",
    "    random.seed(0)\n",
    "    zero_color = (0,0,0)\n",
    "    after_ignore = (128, 64,128)\n",
    "    colors = [zero_color, (0, 0, 255), (142, 47, 69), (255, 0, 0), (0, 255, 255), (0, 214, 193), (129, 0, 180),\n",
    "             (1, 166, 65), (0, 134, 255), (66, 45, 136), (255, 255, 0), after_ignore]\n",
    "    #colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
    "\n",
    "    n_classes = 12\n",
    "    H, W = 224, 224\n",
    "    seg_arr = model.predict(img.reshape(1, H, W, 3))[0]\n",
    "    seg_arr = seg_arr.reshape((H, W, n_classes)).argmax(axis=2)\n",
    "    seg_arr = seg_arr.astype(np.uint8)\n",
    "    print(seg_arr.shape, np.unique(seg_arr))\n",
    "    seg_img = np.zeros((H, W, 3))\n",
    "    for c in range(n_classes):\n",
    "      seg_arr_c = seg_arr[:, :] == c\n",
    "      seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "      seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "      seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "    seg_img = seg_img.astype(np.uint8)\n",
    "    plt.imshow(seg_img),plt.show()\n",
    "\n",
    "    \n",
    "#visalize_prediction(model, X_train[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
