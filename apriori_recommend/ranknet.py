# -*- coding: utf-8 -*-
"""RankNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fdR_DDdFXN-BNxIEL_1rAYGWrftMcQAS
"""

import numpy as np
import pandas as pd
import collections 
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from collections import OrderedDict
from gensim import models
from gensim.models.doc2vec import LabeledSentence
import tensorflow as tf
from keras.utils import print_summary
from keras.applications.inception_v3 import InceptionV3
from keras.utils import multi_gpu_model
from keras.optimizers import SGD, RMSprop, Adam
from keras.callbacks import History, LearningRateScheduler, ModelCheckpoint, Callback
from keras import layers
from keras.models import Model, save_model, Sequential
from keras.layers import Activation, Concatenate, AveragePooling2D, BatchNormalization
from keras.layers import Conv2D, Dense, Input, Lambda, GlobalMaxPooling2D,LSTM, Dropout, Lambda
from keras.layers import MaxPooling2D, GlobalAveragePooling2D
from keras import backend as K
from sklearn.model_selection import train_test_split
# %matplotlib inline

def dataset(csv_path, target_name):
  df=pd.read_csv(csv_path)
  #df=pd.read_csv('division_rank.csv')
  df=df.drop('Unnamed: 0', axis=1)

  
  # ラベル
  target=np.array(df[target_name])
  target=pd.DataFrame(target) 

  # 特徴量
  data=df.drop(target_name, axis=1)
  f1_columns=list(data.columns)

  # 特徴量の標準化
  f1_columns=list(data.columns)
  sc = StandardScaler()
  dff = sc.fit_transform(data)
  dff=pd.DataFrame(dff)
  dff.columns=f1_columns
  print(dff.shape)
  
  # ラベルの標準化
  t = sc.fit_transform(target)
  t=np.reshape(t, (len(t),))
  print(t.shape)
  
  X_train, X_test, y_train, y_test = train_test_split(dff, t, test_size=0.3)
  return X_train, X_test, y_train, y_test 


def Ranknet(INPUT_DIM):
    model = Sequential()
    model.add(Dense(INPUT_DIM, input_dim=INPUT_DIM, activation='relu'))
    model.add(Dropout(0.1))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.1))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

X_train, X_test, y_train, y_test = dataset('rank.csv', 'rank'):  
model=Ranknet(8)
print_summary(model)


# train
history=model.fit(X_train, y_train, epochs=2, verbose=1)

# prediction
pred = model.predict(X_test, verbose=1, steps=1)
print(pred.shape)

y_test=np.reshape(y_test, (len(y_test),))
pred=np.reshape(pred, (len(pred),))
print(pred.min())
print(pred.max())
print(len(collections.Counter(pred)))


# evaluation by NDCG

def ndcg(y_true, y_score, k=100):
    y_true = y_true.ravel()
    y_score = y_score.ravel()
    y_true_sorted = sorted(y_true, reverse=True)
    ideal_dcg = 0
    for i in range(k):
        ideal_dcg += (2 ** y_true_sorted[i] - 1.) / np.log2(i + 2)
    dcg = 0
    argsort_indices = np.argsort(y_score)[::-1]
    for i in range(k):
        dcg += (2 ** y_true[argsort_indices[i]] - 1.) / np.log2(i + 2)
    ndcg = dcg / ideal_dcg
    return ndcg

print(ndcg(y_test, pred))


# save model 
model.save('/home/ubuntu/c_point/rank_model.h5')